########################
# Additional Files
########################
# runs
# results
# inception
# __pycache__
# README.md
# .DS_Store
# data

########################
# Filled Code
########################
# ../codes/GAN/trainer.py:1
        D_x = self._netD(real_imgs)
        loss_D_real = BCE_criterion(D_x, torch.ones_like(D_x))
        #nn.BCELoss has `default = mean`, so the loss has been automatically computed as average loss over instances in a batch
        D_x = D_x.mean()
        loss_D_real.backward()

# ../codes/GAN/trainer.py:2
        D_G_z1 = self._netD(fake_imgs)
        loss_D_fake = BCE_criterion(D_G_z1, torch.zeros_like(D_G_z1))
        D_G_z1 = D_G_z1.mean()
        loss_D_fake.backward(retain_graph = True)

# ../codes/GAN/trainer.py:3
        D_G_z2 = self._netD(fake_imgs)
        loss_G = BCE_criterion(D_G_z2, torch.ones_like(D_G_z2))
        D_G_z2 = D_G_z2.mean()

# ../codes/GAN/GAN.py:1
            nn.ConvTranspose2d(self.latent_dim, 4*self.hidden_dim, 4, 1, 0),
            nn.BatchNorm2d(4*self.hidden_dim),
            nn.ReLU(),
            nn.ConvTranspose2d(4*self.hidden_dim, 2*self.hidden_dim, 4, 2, 1),
            nn.BatchNorm2d(2*self.hidden_dim),
            nn.ReLU(),
            nn.ConvTranspose2d(2*self.hidden_dim, self.hidden_dim, 4, 2, 1),
            nn.BatchNorm2d(self.hidden_dim),
            nn.ReLU(),
            nn.ConvTranspose2d(self.hidden_dim, 1, 4, 2, 1),
            nn.Tanh()


########################
# References
########################

########################
# Other Modifications
########################
# _codes/GAN/main.py -> ../codes/GAN/main.py
# 12 + import torchvision
# 18 +     #added for extension
# 19 +     parser.add_argument('--interpolation',action='store_true')
# 20 +     parser.add_argument('--mode_collapse',action ='store_true')
# 21 +     parser.add_argument('--use_mlp',action='store_true')
# 22 +     #end
# 31 -     config = 'z-{}_batch-{}_num-train-steps-{}'.format(args.latent_dim, args.batch_size, args.num_training_steps)
# 37 +     #config = 'z-{}_batch-{}_num-train-steps-{}'.format(args.latent_dim, args.batch_size, args.num_training_steps)
# 37 ?     +
# 38 +     config = 'latent_dim-{}_hidden_dim-{}'.format(args.latent_dim, args.generator_hidden_dim)
# 37 -     netG = GAN.get_generator(1, args.latent_dim, args.generator_hidden_dim, device)
# 44 +     netG = GAN.get_generator(1, args.latent_dim, args.generator_hidden_dim, device, args.use_mlp)
# 44 ?                                                                                   ++++++++++++++
# 38 -     netD = GAN.get_discriminator(1, args.discriminator_hidden_dim, device)
# 45 +     netD = GAN.get_discriminator(1, args.discriminator_hidden_dim, device, args.use_mlp)
# 45 ?                                                                          ++++++++++++++
# 57 +     #interpolation & mode_collapse
# 58 +     if args.interpolation:
# 59 +         for i in range(5):
# 60 +             lower_bound = torch.randn(1,netG.latent_dim,1,1,device=device)
# 61 +             upper_bound = torch.randn(1, netG.latent_dim,1,1,device=device)
# 62 +             difference = upper_bound - lower_bound
# 63 +             latent_sample = lower_bound
# 64 +             for index in range(11):
# 65 +                 interpolation_sample = lower_bound + ((index + 1)/11) * difference
# 66 +                 latent_sample = torch.cat([latent_sample, interpolation_sample], dim=0)
# 67 +             samples = netG.forward(latent_sample)
# 68 +             imgs = torchvision.utils.make_grid(samples,6)
# 69 +             torchvision.utils.save_image(imgs, 'results/interpolation-pair-{}.png'.format(i))
# 70 +     if args.mode_collapse:
# 71 +         samples = netG.forward(torch.randn(50,netG.latent_dim,1,1,device=device))
# 72 +         imgs = torchvision.utils.make_grid(samples,10)
# 73 +         torchvision.utils.save_image(imgs, 'results/mode_collapse.png')
# 74 +     #end
# 75 +     if (not args.interpolation) and (not args.mode_collapse):
# 50 -     num_samples = 3000
# 76 +         num_samples = 3000
# 76 ? ++++
# 51 -     real_imgs = None
# 77 +         real_imgs = None
# 77 ? ++++
# 52 -     real_dl = iter(dataset.training_loader)
# 78 +         real_dl = iter(dataset.training_loader)
# 78 ? ++++
# 53 -     while real_imgs is None or real_imgs.size(0) < num_samples:
# 79 +         while real_imgs is None or real_imgs.size(0) < num_samples:
# 79 ? ++++
# 54 -         imgs = next(real_dl)
# 80 +             imgs = next(real_dl)
# 80 ? ++++
# 55 -         if real_imgs is None:
# 81 +             if real_imgs is None:
# 81 ? ++++
# 56 -             real_imgs = imgs[0]
# 82 +                 real_imgs = imgs[0]
# 82 ? ++++
# 57 -         else:
# 83 +             else:
# 83 ? ++++
# 58 -             real_imgs = torch.cat((real_imgs, imgs[0]), 0)
# 84 +                 real_imgs = torch.cat((real_imgs, imgs[0]), 0)
# 84 ? ++++
# 59 -     real_imgs = real_imgs[:num_samples].expand(-1, 3, -1, -1) * 0.5 + 0.5
# 85 +         real_imgs = real_imgs[:num_samples].expand(-1, 3, -1, -1) * 0.5 + 0.5
# 85 ? ++++
# 61 -     with torch.no_grad():
# 87 +         with torch.no_grad():
# 87 ? ++++
# 62 -         samples = None
# 88 +             samples = None
# 88 ? ++++
# 63 -         while samples is None or samples.size(0) < num_samples:
# 89 +             while samples is None or samples.size(0) < num_samples:
# 89 ? ++++
# 64 -             imgs = netG.forward(torch.randn(args.batch_size, netG.latent_dim, 1, 1, device=device))
# 90 +                 imgs = netG.forward(torch.randn(args.batch_size, netG.latent_dim, 1, 1, device=device))
# 90 ? ++++
# 65 -             if samples is None:
# 91 +                 if samples is None:
# 91 ? ++++
# 66 -                 samples = imgs
# 92 +                     samples = imgs
# 92 ? ++++
# 67 -             else:
# 93 +                 else:
# 93 ? ++++
# 68 -                 samples = torch.cat((samples, imgs), 0)
# 94 +                     samples = torch.cat((samples, imgs), 0)
# 94 ? ++++
# 69 -     samples = samples[:num_samples].expand(-1, 3, -1, -1) * 0.5 + 0.5
# 95 +         samples = samples[:num_samples].expand(-1, 3, -1, -1) * 0.5 + 0.5
# 95 ? ++++
# 70 -     samples = samples.cpu()
# 96 +         samples = samples.cpu()
# 96 ? ++++
# 72 -     fid = fid_score.calculate_fid_given_images(real_imgs, samples, args.batch_size, device)
# 98 +         fid = fid_score.calculate_fid_given_images(real_imgs, samples, args.batch_size, device)
# 98 ? ++++
# 73 -     tb_writer.add_scalar('fid', fid)
# 99 +         tb_writer.add_scalar('fid', fid)
# 99 ? ++++
# 74 -     print("FID score: {:.3f}".format(fid), flush=True)
# 100 +         print("FID score: {:.3f}".format(fid), flush=True)
# 100 ? ++++
# _codes/GAN/GAN.py -> ../codes/GAN/GAN.py
# 12 +     #For MLP-based GAN
# 13 +     elif classname.find('Linear') != -1:
# 14 +         torch.nn.init.normal_(m.weight,0.0,0.02)
# 15 +         torch.nn.init.zeros_(m.bias)
# 13 - def get_generator(num_channels, latent_dim, hidden_dim, device):
# 17 + def get_generator(num_channels, latent_dim, hidden_dim, device, use_mlp=False):
# 17 ?                                                               +++++++++++++++
# 14 -     model = Generator(num_channels, latent_dim, hidden_dim).to(device)
# 18 +     model = Generator(num_channels, latent_dim, hidden_dim, use_mlp).to(device)
# 18 ?                                                           +++++++++
# 18 - def get_discriminator(num_channels, hidden_dim, device):
# 22 + def get_discriminator(num_channels, hidden_dim, device, use_mlp=False):
# 22 ?                                                       +++++++++++++++
# 19 -     model = Discriminator(num_channels, hidden_dim).to(device)
# 23 +     model = Discriminator(num_channels, hidden_dim, use_mlp).to(device)
# 23 ?                                                   +++++++++
# 24 -     def __init__(self, num_channels, latent_dim, hidden_dim):
# 28 +     def __init__(self, num_channels, latent_dim, hidden_dim, use_mlp=False):
# 28 ?                                                            +++++++++++++++
# 33 +         self.use_mlp = use_mlp
# 50 +         self.linear_decoder = nn.Sequential(#latent_dim=100
# 51 +             nn.Linear(self.latent_dim, 256),
# 52 +             nn.LeakyReLU(0.2, inplace=True),
# 53 +             nn.BatchNorm1d(256),
# 54 +
# 55 +             nn.Linear(256, 512),
# 56 +             nn.LeakyReLU(0.2, inplace=True),
# 57 +             nn.BatchNorm1d(512),
# 58 +
# 59 +             nn.Linear(512, 1024),
# 60 +             nn.Tanh()
# 61 +             )
# 69 +         if self.use_mlp:
# 70 +             batch_size = z.shape[0]
# 71 +             decoder_output = self.linear_decoder(z.reshape((batch_size,-1)))
# 72 +             return decoder_output.reshape((batch_size,self.num_channels,32,32))
# 62 -     def __init__(self, num_channels, hidden_dim):
# 93 +     def __init__(self, num_channels, hidden_dim, use_mlp=False):
# 93 ?                                                +++++++++++++++
# 97 +         self.use_mlp = use_mlp
# 114 +         self.linear_clf = nn.Sequential(
# 115 +             nn.Linear(num_channels*32*32, 512),
# 116 +             nn.LeakyReLU(0.2, inplace=True),
# 117 +             nn.Linear(512, 256),
# 118 +             nn.BatchNorm1d(256),
# 119 +             nn.LeakyReLU(0.2, inplace=True),
# 120 +             nn.Linear(256, 1),
# 121 +             nn.Sigmoid()
# 122 +         )
# 125 +         if self.use_mlp:
# 126 +             return self.linear_clf(x.reshape(x.shape[0],-1)).squeeze(1)

